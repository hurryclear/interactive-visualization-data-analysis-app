{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version4 (tina)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 1. DATA PREPARATION\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Clean the data\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "df['Age'] = np.floor(df['Age'])\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature Scaling\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Models array (2D array for Cross-Validation and Bootstrap)\n",
    "models = {\n",
    "    \"Logistic Regression\": [LogisticRegression(max_iter=1000), LogisticRegression(max_iter=1000)],\n",
    "    \"Decision Tree\": [DecisionTreeClassifier(random_state=42), DecisionTreeClassifier(random_state=42)],\n",
    "    \"KNN (k=3)\": [KNeighborsClassifier(n_neighbors=3), KNeighborsClassifier(n_neighbors=3)],\n",
    "}\n",
    "\n",
    "# Cross-validation method\n",
    "def cross_validate_method(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx] if isinstance(X, pd.DataFrame) else (X[train_idx], X[test_idx])\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx] if isinstance(y, pd.Series) else (y[train_idx], y[test_idx])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics['accuracy'].append(accuracy_score(y[test_idx], y_pred))\n",
    "        metrics['precision'].append(precision_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        metrics['recall'].append(recall_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        metrics['f1'].append(f1_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        confusion_matrices.append(confusion_matrix(y[test_idx], y_pred))\n",
    "\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    avg_metrics = {key: np.mean(value) for key, value in metrics.items()}\n",
    "\n",
    "    return { \n",
    "        **avg_metrics,\n",
    "        'confusion_matrix': avg_confusion_matrix\n",
    "        # 'decision_tree': dt_image\n",
    "    }\n",
    "\n",
    "# Bootstrap method\n",
    "def bootstrap_632_method(model, X, y):\n",
    "    train_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    test_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for _ in range(100):  \n",
    "        # Resample for bootstrap\n",
    "        X_boot, y_boot = resample(X, y, replace=True, n_samples=len(X), random_state=42)\n",
    "\n",
    "        # Berechne die Out-of-Bag (OOB)-Indizes\n",
    "        oob_indices = np.setdiff1d(np.arange(len(X)), np.unique(X_boot, return_index=True)[1])\n",
    "\n",
    "        # Verwende .iloc[] fÃ¼r pandas DataFrame/Series \n",
    "        X_oob = X.iloc[oob_indices] if isinstance(X, pd.DataFrame) else X[oob_indices]\n",
    "        y_oob = y.iloc[oob_indices] if isinstance(y, pd.Series) else y[oob_indices]\n",
    "\n",
    "        # Trainiere das Modell mit den Bootstrap-Daten\n",
    "        model.fit(X_boot, y_boot)\n",
    "        y_pred_train = model.predict(X_boot)\n",
    "\n",
    "        train_metrics['accuracy'].append(accuracy_score(y_boot, y_pred_train))\n",
    "        train_metrics['precision'].append(precision_score(y_boot, y_pred_train, average='weighted', zero_division=0))\n",
    "        train_metrics['recall'].append(recall_score(y_boot, y_pred_train, average='weighted', zero_division=0))\n",
    "        train_metrics['f1'].append(f1_score(y_boot, y_pred_train, average='weighted', zero_division=0))\n",
    "\n",
    "        if len(oob_indices) > 0:\n",
    "            y_pred_oob = model.predict(X_oob)\n",
    "            test_metrics['accuracy'].append(accuracy_score(y_oob, y_pred_oob))\n",
    "            test_metrics['precision'].append(precision_score(y_oob, y_pred_oob, average='weighted', zero_division=0))\n",
    "            test_metrics['recall'].append(recall_score(y_oob, y_pred_oob, average='weighted', zero_division=0))\n",
    "            test_metrics['f1'].append(f1_score(y_oob, y_pred_oob, average='weighted', zero_division=0))\n",
    "            confusion_matrices.append(confusion_matrix(y_oob, y_pred_oob))\n",
    "            \n",
    "    train_metrics_mean = {metric: np.mean(train_metrics[metric]) for metric in train_metrics}\n",
    "    test_metrics_mean = {metric: np.mean(test_metrics[metric]) for metric in test_metrics}\n",
    "\n",
    "    combined_metrics = {metric: 0.368 * train_metrics_mean[metric] + 0.632 * test_metrics_mean[metric] for metric in train_metrics}\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0) if confusion_matrices else None\n",
    "\n",
    "    combined_metrics['confusion_matrix'] = avg_confusion_matrix\n",
    "    return combined_metrics\n",
    "\n",
    "# Visualize Decision Tree (cross-validation and bootstrap)\n",
    "def decision_tree_visualization(model, X, y):\n",
    "    # Visualize the Decision Tree\n",
    "    buf = io.BytesIO()\n",
    "    plt.figure(figsize=(100, 90))\n",
    "    plot_tree(model, feature_names=X.columns, class_names=[\"Not Survived\", \"Survived\"], filled=True)\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    plt.close()\n",
    "    return base64.b64encode(buf.getbuffer()).decode(\"utf8\")\n",
    "\n",
    "# Evaluate models\n",
    "crossval_results = {}\n",
    "bootstrap_results = {}\n",
    "decision_tree_cv = {}\n",
    "decision_tree_bs = {}\n",
    "\n",
    "for model_name, model_pair in models.items():\n",
    "    crossval_results[model_name] = cross_validate_method(model_pair[0], X, y)\n",
    "    bootstrap_results[model_name] = bootstrap_632_method(model_pair[1], X, y)\n",
    "\n",
    "\n",
    "# For decision tree visualization (cross-validation and bootstrap)\n",
    "decision_tree_cv = decision_tree_visualization(models[\"Decision Tree\"][0], X, y)\n",
    "decision_tree_bootstrap = decision_tree_visualization(models[\"Decision Tree\"][1], X, y)\n",
    "\n",
    "# 3. Build Dash App\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Titanic Classification Models Evaluation\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # Metrics Comparison\n",
    "    html.H3(\"Cross-Validation Metrics Comparison\"),\n",
    "    dcc.Graph(figure=go.Figure(\n",
    "        data=[go.Bar(\n",
    "            x=['accuracy', 'precision', 'recall', 'f1'],\n",
    "            y=[crossval_results[model][metric] for metric in ['accuracy', 'precision', 'recall', 'f1']],\n",
    "            name=model\n",
    "        ) for model in models.keys()],\n",
    "        layout=go.Layout(\n",
    "            barmode='group',\n",
    "            title=\"Cross-Validation Metrics Comparison\",\n",
    "            xaxis=dict(title=\"Metric\"),\n",
    "            yaxis=dict(title=\"Score\")\n",
    "        )\n",
    "    )),\n",
    "    \n",
    "    html.H3(\"Bootstrap Metrics Comparison\"),\n",
    "    dcc.Graph(figure=go.Figure(\n",
    "        data=[go.Bar(\n",
    "            x=['accuracy', 'precision', 'recall', 'f1'],\n",
    "            y=[bootstrap_results[model][metric] for metric in ['accuracy', 'precision', 'recall', 'f1']],\n",
    "            name=model\n",
    "        ) for model in models.keys()],\n",
    "        layout=go.Layout(\n",
    "            barmode='group',\n",
    "            title=\"Bootstrap Metrics Comparison\",\n",
    "            xaxis=dict(title=\"Metric\"),\n",
    "            yaxis=dict(title=\"Score\")\n",
    "        )\n",
    "    )),\n",
    "    html.H3(\"Confusion Matrices: Cross-Validation\"),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(figure=px.imshow(crossval_results[model]['confusion_matrix'], text_auto=True,\n",
    "                                        title=f\"{model}\",\n",
    "                                        color_continuous_scale='Blues').update_layout(\n",
    "                                            autosize=False,\n",
    "                                            width=300,\n",
    "                                            height=300\n",
    "                                        ))\n",
    "        ], style={'margin': '10px'})\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row', 'flexWrap': 'wrap'}),\n",
    "    \n",
    "    html.H3(\"Confusion Matrices: Bootstrap\"),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(figure=px.imshow(bootstrap_results[model]['confusion_matrix'], text_auto=True,\n",
    "                                        title=f\"{model}\",\n",
    "                                        color_continuous_scale='Reds').update_layout(\n",
    "                                            autosize=False,\n",
    "                                            width=300,\n",
    "                                            height=300\n",
    "                                        ))\n",
    "        ], style={'margin': '10px'})\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row', 'flexWrap': 'wrap'}),\n",
    "\n",
    "    \n",
    "\n",
    "    # Decision Tree visualizations\n",
    "    html.H3(\"Decision Tree (Cross-Validation)\"),\n",
    "    html.Img(src=\"data:image/png;base64,{}\".format(decision_tree_cv), style={'width': '100%', 'height': 'auto'}),\n",
    "\n",
    "    html.H3(\"Decision Tree (Bootstrap)\"),\n",
    "    html.Img(src=\"data:image/png;base64,{}\".format(decision_tree_bootstrap), style={'width': '100%', 'height': 'auto'})\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 5 (huo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/1tjj64zd37sdph6807cm97nh0000gn/T/ipykernel_59596/435906534.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17fd167e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 1. DATA PREPARATION\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Clean the data\n",
    "# These columns (PassengerId, Name, Ticket, Cabin) are not useful for predicting survival. They either contain unique identifiers or non-informative text data that do not contribute to the model's predictive power.\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "# The 'Age' column has missing values. Using the median to fill these gaps is a common practice because it is robust to outliers and provides a central tendency measure.\n",
    "df['Age'] = np.floor(df['Age'])\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# The 'Embarked' column has missing values. Filling them with the most frequent value.\n",
    "# df['Embarked'] = df['Embarked'].astype('category')\n",
    "# df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# df['Sex'] = df['Sex'].astype('category')\n",
    "\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "\n",
    "# Features and target: To prepare the data for modeling, we need to separate the features (input variables) from the target (output variable).\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature Scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Models array (2D array for Cross-Validation and Bootstrap)\n",
    "models = {\n",
    "    \"Logistic Regression\": [LogisticRegression(max_iter=1000), LogisticRegression(max_iter=1000)],\n",
    "    \"Decision Tree\": [DecisionTreeClassifier(random_state=42), DecisionTreeClassifier(random_state=42)],\n",
    "    \"KNN (k=3)\": [KNeighborsClassifier(n_neighbors=3), KNeighborsClassifier(n_neighbors=3)],\n",
    "}\n",
    "\n",
    "# def train_model(model, data_train):\n",
    "#     \"\"\"Trains the model on the training data.\"\"\"\n",
    "#     for data in data_train:\n",
    "#         X_train, y_train = data[:2]  # Only use the first two values\n",
    "#         model.fit(X_train, y_train)\n",
    "#     return model\n",
    "\n",
    "# def cross_validation_data(X, y):\n",
    "#     \"\"\"Generates train-test splits for cross-validation.\"\"\"\n",
    "#     cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "#     data_train = []\n",
    "#     data_test = []\n",
    "\n",
    "#     for train_idx, test_idx in cv.split(X, y):\n",
    "#         X_train, X_test = X[train_idx], X[test_idx]\n",
    "#         y_train, y_test = y[train_idx], y[test_idx]\n",
    "#         data_train.append((X_train, y_train))\n",
    "#         data_test.append((X_test, y_test))\n",
    "\n",
    "#     return data_train, data_test\n",
    "\n",
    "# Cross-validation method\n",
    "def cross_validate_method(model, X, y):\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "    # all_predictions = []\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx] if isinstance(X, pd.DataFrame) else (X[train_idx], X[test_idx])\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx] if isinstance(y, pd.Series) else (y[train_idx], y[test_idx])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # all_predictions.append((X_test, y_test, y_pred))  # Store predictions and test labels\n",
    "\n",
    "        metrics['accuracy'].append(accuracy_score(y[test_idx], y_pred))\n",
    "        metrics['precision'].append(precision_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        metrics['recall'].append(recall_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        metrics['f1'].append(f1_score(y[test_idx], y_pred, average='weighted', zero_division=0))\n",
    "        confusion_matrices.append(confusion_matrix(y[test_idx], y_pred))\n",
    "\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    avg_metrics = {key: np.mean(value) for key, value in metrics.items()}\n",
    "\n",
    "    return { \n",
    "        **avg_metrics,\n",
    "        'confusion_matrix': avg_confusion_matrix\n",
    "        # 'decision_tree': dt_image\n",
    "    }\n",
    "\n",
    "# Bootstrap method\n",
    "def bootstrap_632_method(model, X, y):\n",
    "    train_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    test_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "    confusion_matrices = []\n",
    "    # all_predictions = []\n",
    "\n",
    "    for _ in range(100):  \n",
    "        # Resample for bootstrap\n",
    "        X_train, y_train = resample(X, y, replace=True, n_samples=len(X), random_state=42)\n",
    "\n",
    "        # get incides for out-of-bag samples (for test)\n",
    "        test_indices = np.setdiff1d(np.arange(len(X)), np.unique(X_train, return_index=True)[1])\n",
    "\n",
    "        # Verwende .iloc[] fÃ¼r pandas DataFrame/Series \n",
    "        X_test = X.iloc[test_indices] if isinstance(X, pd.DataFrame) else X[test_indices]\n",
    "        y_test = y.iloc[test_indices] if isinstance(y, pd.Series) else y[test_indices]\n",
    "\n",
    "        # Trainiere das Modell mit den Bootstrap-Daten\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "\n",
    "        train_metrics['accuracy'].append(accuracy_score(y_train, y_pred_train))\n",
    "        train_metrics['precision'].append(precision_score(y_train, y_pred_train, average='weighted', zero_division=0))\n",
    "        train_metrics['recall'].append(recall_score(y_train, y_pred_train, average='weighted', zero_division=0))\n",
    "        train_metrics['f1'].append(f1_score(y_train, y_pred_train, average='weighted', zero_division=0))\n",
    "\n",
    "        if len(test_indices) > 0:\n",
    "            \n",
    "            y_pred_oob = model.predict(X_test)\n",
    "            # all_predictions.append((X_test, y_test, y_pred_oob))  # Store predictions and test labels\n",
    "\n",
    "            test_metrics['accuracy'].append(accuracy_score(y_test, y_pred_oob))\n",
    "            test_metrics['precision'].append(precision_score(y_test, y_pred_oob, average='weighted', zero_division=0))\n",
    "            test_metrics['recall'].append(recall_score(y_test, y_pred_oob, average='weighted', zero_division=0))\n",
    "            test_metrics['f1'].append(f1_score(y_test, y_pred_oob, average='weighted', zero_division=0))\n",
    "            confusion_matrices.append(confusion_matrix(y_test, y_pred_oob))\n",
    "            \n",
    "    train_metrics_mean = {metric: np.mean(train_metrics[metric]) for metric in train_metrics}\n",
    "    test_metrics_mean = {metric: np.mean(test_metrics[metric]) for metric in test_metrics}\n",
    "\n",
    "    combined_metrics = {metric: 0.368 * train_metrics_mean[metric] + 0.632 * test_metrics_mean[metric] for metric in train_metrics}\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0) if confusion_matrices else None\n",
    "\n",
    "    combined_metrics['confusion_matrix'] = avg_confusion_matrix\n",
    "    return combined_metrics\n",
    "\n",
    "# Visualize Decision Tree (cross-validation and bootstrap)\n",
    "def decision_tree_visualization(model, feature_names):\n",
    "    # Visualize the Decision Tree\n",
    "    buf = io.BytesIO()\n",
    "    plt.figure(figsize=(100, 90))\n",
    "    plot_tree(model, feature_names=feature_names, filled=True)\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    plt.close()\n",
    "    return base64.b64encode(buf.getbuffer()).decode(\"utf8\")\n",
    "\n",
    "# Evaluate models\n",
    "crossval_results = {}\n",
    "bootstrap_results = {}\n",
    "decision_tree_cv = {}\n",
    "decision_tree_bs = {}\n",
    "\n",
    "for model_name, model_pair in models.items():\n",
    "    crossval_results[model_name] = cross_validate_method(model_pair[0], X, y)\n",
    "    bootstrap_results[model_name] = bootstrap_632_method(model_pair[1], X, y)\n",
    "\n",
    "\n",
    "# For decision tree visualization (cross-validation and bootstrap)\n",
    "decision_tree_cv = decision_tree_visualization(models[\"Decision Tree\"][0], X.columns)\n",
    "decision_tree_bootstrap = decision_tree_visualization(models[\"Decision Tree\"][1], X.columns)\n",
    "\n",
    "# 3. Build Dash App\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Titanic Classification Models Evaluation\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # Metrics Comparison\n",
    "    html.H3(\"Cross-Validation Metrics Comparison\"),\n",
    "    dcc.Graph(figure=go.Figure(\n",
    "        data=[go.Bar(\n",
    "            x=['accuracy', 'precision', 'recall', 'f1'],\n",
    "            y=[crossval_results[model][metric] for metric in ['accuracy', 'precision', 'recall', 'f1']],\n",
    "            name=model\n",
    "        ) for model in models.keys()],\n",
    "        layout=go.Layout(\n",
    "            barmode='group',\n",
    "            title=\"Cross-Validation Metrics Comparison\",\n",
    "            xaxis=dict(title=\"Metric\"),\n",
    "            yaxis=dict(title=\"Score\")\n",
    "        )\n",
    "    )),\n",
    "    \n",
    "    html.H3(\"Bootstrap Metrics Comparison\"),\n",
    "    dcc.Graph(figure=go.Figure(\n",
    "        data=[go.Bar(\n",
    "            x=['accuracy', 'precision', 'recall', 'f1'],\n",
    "            y=[bootstrap_results[model][metric] for metric in ['accuracy', 'precision', 'recall', 'f1']],\n",
    "            name=model\n",
    "        ) for model in models.keys()],\n",
    "        layout=go.Layout(\n",
    "            barmode='group',\n",
    "            title=\"Bootstrap Metrics Comparison\",\n",
    "            xaxis=dict(title=\"Metric\"),\n",
    "            yaxis=dict(title=\"Score\")\n",
    "        )\n",
    "    )),\n",
    "    html.H3(\"Confusion Matrices: Cross-Validation\"),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(figure=px.imshow(crossval_results[model]['confusion_matrix'], text_auto=True,\n",
    "                                        title=f\"{model}\",\n",
    "                                        color_continuous_scale='Blues').update_layout(\n",
    "                                            autosize=False,\n",
    "                                            width=300,\n",
    "                                            height=300\n",
    "                                        ))\n",
    "        ], style={'margin': '10px'})\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row', 'flexWrap': 'wrap'}),\n",
    "    \n",
    "    html.H3(\"Confusion Matrices: Bootstrap\"),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(figure=px.imshow(bootstrap_results[model]['confusion_matrix'], text_auto=True,\n",
    "                                        title=f\"{model}\",\n",
    "                                        color_continuous_scale='Reds').update_layout(\n",
    "                                            autosize=False,\n",
    "                                            width=300,\n",
    "                                            height=300\n",
    "                                        ))\n",
    "        ], style={'margin': '10px'})\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row', 'flexWrap': 'wrap'}),\n",
    "\n",
    "    \n",
    "\n",
    "    # Decision Tree visualizations\n",
    "    html.H3(\"Decision Tree (Cross-Validation)\"),\n",
    "    html.Img(src=\"data:image/png;base64,{}\".format(decision_tree_cv), style={'width': '100%', 'height': 'auto'}),\n",
    "\n",
    "    html.H3(\"Decision Tree (Bootstrap)\"),\n",
    "    html.Img(src=\"data:image/png;base64,{}\".format(decision_tree_bootstrap), style={'width': '100%', 'height': 'auto'})\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
