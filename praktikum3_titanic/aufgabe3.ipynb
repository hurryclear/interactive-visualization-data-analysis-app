{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicates\n",
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen der Spalte 'Cabin' aus dem DataFrame weil 77% missing values\n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "#Age abrunden\n",
    "df['Age'] = np.floor(df['Age'])\n",
    "#missing values treatment\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True) # ist's sinvoll?\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values\n",
    "df.isnull().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrahiere new column 'Titel',das könnte wichtig für datenanalyse sein?\n",
    "df[\"Title\"] = df[\"Name\"].apply(lambda x: x.split(\",\")[1].split(\".\")[0].strip())\n",
    "df[\"Name\"] = df[\"Name\"].apply(lambda x: ' '.join([word for word in x.split() if not word.endswith('.')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import base64\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, make_scorer, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "\n",
    "# 1. DATA PREPARATION\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Clean the data\n",
    "# These columns (PassengerId, Name, Ticket, Cabin) are not useful for predicting survival. They either contain unique identifiers or non-informative text data that do not contribute to the model's predictive power.\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "# The 'Age' column has missing values. Using the median to fill these gaps is a common practice because it is robust to outliers and provides a central tendency measure.\n",
    "df['Age'] = np.floor(df['Age'])\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "# The 'Embarked' column has missing values. Filling them with the most frequent value.\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "# Features and target: To prepare the data for modeling, we need to separate the features (input variables) from the target (output variable).\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "# Cross-validation and Bootstrap methods\n",
    "def cross_validate_method(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': make_scorer(precision_score, average='weighted'),\n",
    "        'recall': make_scorer(recall_score, average='weighted'),\n",
    "        'f1': make_scorer(f1_score, average='weighted')\n",
    "    }\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, return_estimator=True)\n",
    "    \n",
    "    confusion_matrices = []\n",
    "    for estimator, (train_index, test_index) in zip(scores['estimator'], cv.split(X, y)):\n",
    "        y_pred = estimator.predict(X[test_index])\n",
    "        cm = confusion_matrix(y[test_index], y_pred)\n",
    "        confusion_matrices.append(cm)\n",
    "    \n",
    "    mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': scores['test_accuracy'].mean(),\n",
    "        'precision': scores['test_precision'].mean(),\n",
    "        'recall': scores['test_recall'].mean(),\n",
    "        'f1': scores['test_f1'].mean(),\n",
    "        'confusion_matrix': mean_confusion_matrix\n",
    "    }\n",
    "\n",
    "def bootstrap_632_method(model, X, y):\n",
    "    \"\"\"Perform Bootstrap .632 method with extended metrics.\"\"\"\n",
    "    train_metrics, test_metrics = [], []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for _ in range(100):  # Number of bootstrap iterations\n",
    "        # Bootstrap sampling\n",
    "        bootstrap_indices = np.random.choice(np.arange(len(X)), size=len(X), replace=True)\n",
    "        oob_mask = ~np.isin(np.arange(len(X)), bootstrap_indices)\n",
    "        \n",
    "        X_boot, y_boot = X[bootstrap_indices], y[bootstrap_indices]\n",
    "        X_oob, y_oob = X[oob_mask], y[oob_mask]\n",
    "\n",
    "        # Train the model on in-bag data\n",
    "        model.fit(X_boot, y_boot)\n",
    "        y_pred_train = model.predict(X_boot)\n",
    "\n",
    "        # Collect train metrics\n",
    "        train_metrics.append({\n",
    "            'accuracy': accuracy_score(y_boot, y_pred_train),\n",
    "            'precision': precision_score(y_boot, y_pred_train, average='weighted'),\n",
    "            'recall': recall_score(y_boot, y_pred_train, average='weighted'),\n",
    "            'f1': f1_score(y_boot, y_pred_train, average='weighted'),\n",
    "        })\n",
    "\n",
    "        # Collect test metrics if there are out-of-bag samples\n",
    "        if len(y_oob) > 0:\n",
    "            y_pred_oob = model.predict(X_oob)\n",
    "            test_metrics.append({\n",
    "                'accuracy': accuracy_score(y_oob, y_pred_oob),\n",
    "                'precision': precision_score(y_oob, y_pred_oob, average='weighted'),\n",
    "                'recall': recall_score(y_oob, y_pred_oob, average='weighted'),\n",
    "                'f1': f1_score(y_oob, y_pred_oob, average='weighted'),\n",
    "            })\n",
    "            confusion_matrices.append(confusion_matrix(y_oob, y_pred_oob))\n",
    "\n",
    "    # Aggregate train and test metrics\n",
    "    train_metrics_mean = {metric: np.mean([m[metric] for m in train_metrics]) for metric in train_metrics[0]}\n",
    "    test_metrics_mean = {metric: np.mean([m[metric] for m in test_metrics]) for metric in test_metrics[0]}\n",
    "\n",
    "    # Combine metrics using the .632 formula\n",
    "    combined_metrics = {metric: 0.368 * train_metrics_mean[metric] + 0.632 * test_metrics_mean[metric] for metric in train_metrics_mean}\n",
    "    mean_confusion_matrix = np.mean(confusion_matrices, axis=0) if confusion_matrices else None\n",
    "\n",
    "    combined_metrics['confusion_matrix'] = mean_confusion_matrix\n",
    "    return combined_metrics\n",
    "\n",
    "# Evaluate models\n",
    "metrics_results = {}\n",
    "confusion_matrices = {}\n",
    "crossval_results = {}\n",
    "bootstrap_results = {}\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Cross-validation\n",
    "    crossval_metrics = cross_validate_method(model, X, y)\n",
    "    \n",
    "    # Bootstrap\n",
    "    bootstrap_metrics = bootstrap_632_method(model, X, y)\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_results[model_name] = {\n",
    "        'CrossVal Accuracy': crossval_metrics['accuracy'],\n",
    "        'CrossVal Precision': crossval_metrics['precision'],\n",
    "        'CrossVal Recall': crossval_metrics['recall'],\n",
    "        'CrossVal F1-Score': crossval_metrics['f1'],\n",
    "        'Bootstrap Accuracy': bootstrap_metrics['accuracy'],\n",
    "        'Bootstrap Precision': bootstrap_metrics['precision'],\n",
    "        'Bootstrap Recall': bootstrap_metrics['recall'],\n",
    "        'Bootstrap F1-Score': bootstrap_metrics['f1']\n",
    "    }\n",
    "    \n",
    "    # Save confusion matrices\n",
    "    crossval_results[model_name] = crossval_metrics['confusion_matrix']\n",
    "    bootstrap_results[model_name] = bootstrap_metrics['confusion_matrix']\n",
    "\n",
    "# 3. Build Dash App\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Titanic Classification Models\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # Performance Metrics\n",
    "    html.H3(\"Performance Metrics\"),\n",
    "    dcc.Graph(figure=px.bar(\n",
    "        pd.DataFrame(metrics_results).reset_index(),\n",
    "        x='index', y=list(models.keys()),\n",
    "        barmode='group',\n",
    "        title=\"Performance Metrics for All Models\",\n",
    "        labels={'index': 'Metrics', 'value': 'Score'}\n",
    "    )),\n",
    "\n",
    "    html.H3(\"Confusion Matrices\"),\n",
    "    html.Div([\n",
    "        dcc.Graph(figure=px.imshow(confusion_matrices[model], text_auto=True, title=f\"{model}\", width=300, height=300))\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row'}),\n",
    "\n",
    "    # Cross-validation\n",
    "    html.H3(\"Cross-Validation Results\"),\n",
    "    dcc.Graph(figure=px.line(\n",
    "        x=list(range(1, 11)),\n",
    "        y=[crossval_results[model] for model in models.keys()],\n",
    "        title=\"Cross-Validation Accuracy (10-Fold)\",\n",
    "        labels={'x': 'Fold', 'y': 'Accuracy', 'color': 'Models'}\n",
    "    )),\n",
    "\n",
    "    # Bootstrap .632 Results\n",
    "    html.H3(\"Bootstrap .632 Results\"),\n",
    "    dcc.Graph(figure=px.bar(\n",
    "        x=list(models.keys()),\n",
    "        y=[bootstrap_results[model] for model in models.keys()],\n",
    "        title=\"Bootstrap .632 Accuracy\",\n",
    "        labels={'x': 'Model', 'y': 'Bootstrap Accuracy', 'color': 'Models'},\n",
    "        color=list(models.keys())\n",
    "    )),\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/1tjj64zd37sdph6807cm97nh0000gn/T/ipykernel_31670/371262913.py:24: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n",
      "/var/folders/y1/1tjj64zd37sdph6807cm97nh0000gn/T/ipykernel_31670/371262913.py:25: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17cd57470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import base64\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "\n",
    "# 1. DATA PREPARATION\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Data Cleaning\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], errors='ignore')\n",
    "df['Age'] = np.floor(df['Age'])\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "# Cross-validation and Bootstrap methods\n",
    "def cross_validate_method(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    return cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "def bootstrap_632_method(model, X, y):\n",
    "    train_acc, test_acc = [], []\n",
    "    for _ in range(100):\n",
    "        X_boot, y_boot = resample(X, y, replace=True)\n",
    "        X_oob = X[~np.in1d(np.arange(X.shape[0]), X_boot.index)]\n",
    "        y_oob = y[~np.in1d(np.arange(y.shape[0]), X_boot.index)]\n",
    "        model.fit(X_boot, y_boot)\n",
    "        acc_train = accuracy_score(y_boot, model.predict(X_boot))\n",
    "        acc_test = accuracy_score(y_oob, model.predict(X_oob)) if len(y_oob) > 0 else 0\n",
    "        train_acc.append(acc_train)\n",
    "        test_acc.append(acc_test)\n",
    "    return np.mean(0.368 * np.array(train_acc) + 0.632 * np.array(test_acc))\n",
    "\n",
    "# Evaluate models\n",
    "metrics_results = {}\n",
    "confusion_matrices = {}\n",
    "crossval_results = {}\n",
    "bootstrap_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_results[model_name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    confusion_matrices[model_name] = confusion_matrix(y_test, y_pred)\n",
    "    crossval_results[model_name] = cross_validate_method(model, X, y)\n",
    "    bootstrap_results[model_name] = bootstrap_632_method(model, X, y)\n",
    "\n",
    "# 3. Build Dash App\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Titanic Classification Models\", style={'textAlign': 'center'}),\n",
    "\n",
    "    # Performance Metrics\n",
    "    html.H3(\"Performance Metrics\"),\n",
    "    dcc.Graph(figure=px.bar(\n",
    "        pd.DataFrame(metrics_results).reset_index(),\n",
    "        x='index', y=list(models.keys()),\n",
    "        barmode='group',\n",
    "        title=\"Performance Metrics for All Models\",\n",
    "        labels={'index': 'Metrics', 'value': 'Score'}\n",
    "    )),\n",
    "\n",
    "    # Confusion Matrices\n",
    "    html.H3(\"Confusion Matrices\"),\n",
    "    html.Div([\n",
    "        dcc.Graph(figure=px.imshow(confusion_matrices[model], text_auto=True, title=f\"Confusion Matrix: {model}\", width=300, height=300))\n",
    "        for model in models.keys()\n",
    "    ], style={'display': 'flex', 'flexDirection': 'row', 'flexWrap': 'wrap'}),\n",
    "    \n",
    "    # Cross-validation\n",
    "    html.H3(\"Cross-Validation Results\"),\n",
    "    dcc.Graph(figure=px.line(\n",
    "        x=list(range(1, 11)),\n",
    "        y=[crossval_results[model] for model in models.keys()],\n",
    "        title=\"Cross-Validation Accuracy (10-Fold)\",\n",
    "        labels={'x': 'Fold', 'y': 'Accuracy', 'color': 'Models'}\n",
    "    )),\n",
    "\n",
    "    # Bootstrap .632 Results\n",
    "    html.H3(\"Bootstrap .632 Results\"),\n",
    "    dcc.Graph(figure=px.bar(\n",
    "        x=list(models.keys()),\n",
    "        y=[bootstrap_results[model] for model in models.keys()],\n",
    "        title=\"Bootstrap .632 Accuracy\",\n",
    "        labels={'x': 'Model', 'y': 'Bootstrap Accuracy'},\n",
    "        color=list(models.keys()),\n",
    "        # color_discrete_sequence=px.colors.qualitative.Set1\n",
    "    )),\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
